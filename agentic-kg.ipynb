{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b73e9a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bd1b061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CAAk61Pc4pp1MtlYIYshbRVS9ls0T', created=1756540610, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_80956533cb', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI is ready for use.\n"
     ]
    }
   ],
   "source": [
    "# Define Model Constants for easier use \n",
    "MODEL_GPT = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \n",
    "                                           \"content\": \"Are you ready?\"}], \n",
    "                                tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa7974",
   "metadata": {},
   "source": [
    "## 3.2 Explore `neo4j_for_adk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06bde3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "from neo4j_for_adk import graphdb\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f6582",
   "metadata": {},
   "source": [
    "## 3.3 Define Agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36fbace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic tool -- send a parameterized cypher query\n",
    "def say_hello(person_name: str) -> dict:\n",
    "    \"\"\"Formats a welcome message to a named person. \n",
    "\n",
    "    Args:\n",
    "        person_name (str): the name of the person saying hello\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the results of the query.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'query_result' key with an array of result rows.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    #Neo4j cyoher statement\n",
    "    return graphdb.send_query(\"RETURN 'Hello to you, ' + $person_name AS reply\",\n",
    "    {\n",
    "        \"person_name\": person_name\n",
    "    })\n",
    "    # Error messages\n",
    "    # return {\n",
    "    #     \"status\": \"error\",\n",
    "    #     \"error_message\": \"Something went wrong\"\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66fdc98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'reply': 'Hello to you, ABK'}]}\n",
      "{'status': 'success', 'query_result': [{'reply': \"Hello to you, RETURN 'injection attack avoided'\"}]}\n"
     ]
    }
   ],
   "source": [
    "# Example tool usage (optional test)\n",
    "print(say_hello(\"ABK\"))\n",
    "# Example tool usage (optional test)\n",
    "print(say_hello(\"RETURN 'injection attack avoided'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbccdc7",
   "metadata": {},
   "source": [
    "## 3.4. Define the Agent friendly_cypher_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24baf33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'hello_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher Agent\n",
    "hello_agent = Agent(\n",
    "    name=\"hello_agent_v1\",\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Has friendly chats with a user.\",\n",
    "    instruction=\"\"\"You are a helpful assistant, chatting with a user. \n",
    "                Be polite and friendly, introducing yourself and asking who the user is. \n",
    "\n",
    "                If the user provides their name, use the 'say_hello' tool to get a custom greeting.\n",
    "                If the tool returns an error, inform the user politely. \n",
    "                If the tool is successful, present the reply.\n",
    "                \"\"\",\n",
    "    tools=[say_hello], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{hello_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29eedf",
   "metadata": {},
   "source": [
    "## 3.5. Run the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03206d8",
   "metadata": {},
   "source": [
    "#### 3.5.2. Create the Runner and SessionService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf485ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = hello_agent.name + \"_app\"\n",
    "user_id = hello_agent.name + \"_user\"\n",
    "session_id = hello_agent.name + \"_session_01\"\n",
    "    \n",
    "# Initialize a session service and a session\n",
    "session_service = InMemorySessionService()\n",
    "await session_service.create_session(\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    "    session_id=session_id\n",
    ")\n",
    "    \n",
    "runner = Runner(\n",
    "    agent=hello_agent,\n",
    "    app_name=app_name,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9da4e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: Hello, I'm ABK\n",
      "<<< Agent Response: Hello to you, ABK! I'm glad to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Hello, I'm ABK\"\n",
    "print(f\"\\n>>> User Message: {user_message}\")\n",
    "\n",
    "# Prepare the user's message in ADK format\n",
    "content = types.Content(role='user', parts=[types.Part(text=user_message)])\n",
    "\n",
    "final_response_text = \"Agent did not produce a final response.\" # Default will be replaced if the agent produces a final response.\n",
    "\n",
    "\n",
    "# We iterate through events to find the final answer.\n",
    "verbose = False\n",
    "async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "    if verbose:\n",
    "        print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "    \n",
    "    # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "    if event.is_final_response():\n",
    "        if event.content and event.content.parts:\n",
    "            final_response_text = event.content.parts[0].text # Assuming text response in the first part\n",
    "        elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "            final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "        break # Stop processing events once the final response is found\n",
    "\n",
    "print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7b03c",
   "metadata": {},
   "source": [
    "## 3.6. Create Helper Class: AgentCaller\n",
    "\n",
    "### 3.6.1 Set up AgentCaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4258d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentCaller:\n",
    "    \"\"\"A simple wrapper class for interacting with an ADK agent.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent: Agent, runner: Runner, \n",
    "                 user_id: str, session_id: str):\n",
    "        \"\"\"Initialize the AgentCaller with required components.\"\"\"\n",
    "        self.agent = agent\n",
    "        self.runner = runner\n",
    "        self.user_id = user_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "\n",
    "    def get_session(self):\n",
    "        return self.runner.session_service.get_session(app_name=self.runner.app_name, user_id=self.user_id, session_id=self.session_id)\n",
    "\n",
    "    \n",
    "    async def call(self, user_message: str, verbose: bool = False):\n",
    "        \"\"\"Call the agent with a query and return the response.\"\"\"\n",
    "        print(f\"\\n>>> User Message: {user_message}\")\n",
    "\n",
    "        # Prepare the user's message in ADK format\n",
    "        content = types.Content(role='user', parts=[types.Part(text=user_message)])\n",
    "\n",
    "        final_response_text = \"Agent did not produce a final response.\" \n",
    "        \n",
    "        # Key Concept: run_async executes the agent logic and yields Events.\n",
    "        # We iterate through events to find the final answer.\n",
    "        async for event in self.runner.run_async(user_id=self.user_id, session_id=self.session_id, new_message=content):\n",
    "            # You can uncomment the line below to see *all* events during execution\n",
    "            if verbose:\n",
    "                print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "            # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "            if event.is_final_response():\n",
    "                if event.content and event.content.parts:\n",
    "                    # Assuming text response in the first part\n",
    "                    final_response_text = event.content.parts[0].text\n",
    "                elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "                    final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "                break # Stop processing events once the final response is found\n",
    "\n",
    "        print(f\"<<< Agent Response: {final_response_text}\")\n",
    "        return final_response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e555b0",
   "metadata": {},
   "source": [
    "### 3.6.2 Make an instance of the AgentCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d620aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_agent_caller(agent: Agent, initial_state: Optional[Dict[str, Any]] = {}) -> AgentCaller:\n",
    "    \"\"\"Create and return an AgentCaller instance for the given agent.\"\"\"\n",
    "    app_name = agent.name + \"_app\"\n",
    "    user_id = agent.name + \"_user\"\n",
    "    session_id = agent.name + \"_session_01\"\n",
    "    \n",
    "    # Initialize a session service and a session\n",
    "    session_service = InMemorySessionService()\n",
    "    await session_service.create_session(\n",
    "        app_name=app_name,\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        state=initial_state\n",
    "    )\n",
    "    \n",
    "    runner = Runner(\n",
    "        agent=agent,\n",
    "        app_name=app_name,\n",
    "        session_service=session_service\n",
    "    )\n",
    "    \n",
    "    return AgentCaller(agent, runner, user_id, session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871de1c2",
   "metadata": {},
   "source": [
    "### 3.6.3. Run the Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a445c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: Hello I'm ABK\n",
      "<<< Agent Response: Hello to you, ABK! How can I assist you today?\n",
      "\n",
      ">>> User Message: I am excited\n",
      "<<< Agent Response: That's wonderful to hear, ABK! What's exciting you today?\n"
     ]
    }
   ],
   "source": [
    "hello_agent_caller = await make_agent_caller(hello_agent)\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await hello_agent_caller.call(\"Hello I'm ABK\")\n",
    "\n",
    "    await hello_agent_caller.call(\"I am excited\")\n",
    "\n",
    "# Execute the conversation using await\n",
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179de1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e0a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d57bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-kg-iRiaRh-y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
