{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8957225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from google.adk.agents import LlmAgent, LoopAgent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# For type hints\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9588c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CCpcUgdhXXucj0Pd4S5GNuCqcrhJx', created=1757174398, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad57b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of {feedback} in the string.\n",
    "# Google ADK will replace this from session context if it exists.\n",
    "# Because feedback could be long, XML-like delimiters are included to clarify the content.\n",
    "proposal_agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph modeling with property graphs. Propose an appropriate\n",
    "    schema by specifying construction rules which transform approved files into nodes or relationships.\n",
    "    The resulting schema should describe a knowledge graph based on the user goal.\n",
    "    \n",
    "    Consider feedback if it is available: \n",
    "    <feedback>\n",
    "    {feedback}\n",
    "    </feedback> \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04568250",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_agent_hints = \"\"\"\n",
    "    Every file in the approved files list will become either a node or a relationship.\n",
    "    Determining whether a file likely represents a node or a relationship is based\n",
    "    on a hint from the filename (is it a single thing or two things) and the\n",
    "    identifiers found within the file.\n",
    "\n",
    "    Because unique identifiers are so important for determining the structure of the graph,\n",
    "    always verify the uniqueness of suspected unique identifiers using the 'search_file' tool.\n",
    "\n",
    "    General guidance for identifying a node or a relationship:\n",
    "    - If the file name is singular and has only 1 unique identifier it is likely a node\n",
    "    - If the file name is a combination of two things, it is likely a full relationship\n",
    "    - If the file name sounds like a node, but there are multiple unique identifiers, that is likely a node with reference relationships\n",
    "\n",
    "    Design rules for nodes:\n",
    "    - Nodes will have unique identifiers. \n",
    "    - Nodes _may_ have identifiers that are used as reference relationships.\n",
    "\n",
    "    Design rules for relationships:\n",
    "    - Relationships appear in two ways: full relationships and reference relationships.\n",
    "\n",
    "    Full relationships:\n",
    "    - Full relationships appear in dedicated relationship files, often having a filename that references two entities\n",
    "    - Full relationships typically have references to a source and destination node.\n",
    "    - Full relationships _do not have_ unique identifiers, but instead have references to the primary keys of the source and destination nodes.\n",
    "    - The absence of a single, unique identifier is a strong indicator that a file is a full relationship.\n",
    "    \n",
    "    Reference relationships:\n",
    "    - Reference relationships appear as foreign key references in node files\n",
    "    - Reference relationship foreign key column names often hint at the destination node and relationship type\n",
    "    - References may be hierarchical container relationships, with terminology revealing parent-child, \"has\", \"contains\", membership, or similar relationship\n",
    "    - References may be peer relationships, that is often a self-reference to a similar class of nodes. For example, \"knows\" or \"see also\"\n",
    "\n",
    "    The resulting schema should be a connected graph, with no isolated components.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a888d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - get the user goal using the 'get_approved_user_goal' tool\n",
    "    - get the list of approved files using the 'get_approved_files' tool\n",
    "    - get the current construction plan using the 'get_proposed_construction_plan' tool\n",
    "\n",
    "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
    "    1. For each approved file, consider whether it represents a node or relationship. Check the content for potential unique identifiers using the 'sample_file' tool.\n",
    "    2. For each identifier, verify that it is unique by using the 'search_file' tool.\n",
    "    3. Use the node vs relationship guidance for deciding whether the file represents a node or a relationship.\n",
    "    4. For a node file, propose a node construction using the 'propose_node_construction' tool. \n",
    "    5. If the node contains a reference relationship, use the 'propose_relationship_construction' tool to propose a relationship construction. \n",
    "    6. For a relationship file, propose a relationship construction using the 'propose_relationship_construction' tool\n",
    "    7. If you need to remove a construction, use the 'remove_node_construction' or 'remove_relationship_construction' tool\n",
    "    8. When you are done with construction proposals, use the 'get_proposed_construction_plan' tool to present the plan to the user\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc549b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    You are an expert at knowledge graph modeling with property graphs. Propose an appropriate\n",
      "    schema by specifying construction rules which transform approved files into nodes or relationships.\n",
      "    The resulting schema should describe a knowledge graph based on the user goal.\n",
      "\n",
      "    Consider feedback if it is available: \n",
      "    <feedback>\n",
      "    {feedback}\n",
      "    </feedback> \n",
      "\n",
      "\n",
      "    Every file in the approved files list will become either a node or a relationship.\n",
      "    Determining whether a file likely represents a node or a relationship is based\n",
      "    on a hint from the filename (is it a single thing or two things) and the\n",
      "    identifiers found within the file.\n",
      "\n",
      "    Because unique identifiers are so important for determining the structure of the graph,\n",
      "    always verify the uniqueness of suspected unique identifiers using the 'search_file' tool.\n",
      "\n",
      "    General guidance for identifying a node or a relationship:\n",
      "    - If the file name is singular and has only 1 unique identifier it is likely a node\n",
      "    - If the file name is a combination of two things, it is likely a full relationship\n",
      "    - If the file name sounds like a node, but there are multiple unique identifiers, that is likely a node with reference relationships\n",
      "\n",
      "    Design rules for nodes:\n",
      "    - Nodes will have unique identifiers. \n",
      "    - Nodes _may_ have identifiers that are used as reference relationships.\n",
      "\n",
      "    Design rules for relationships:\n",
      "    - Relationships appear in two ways: full relationships and reference relationships.\n",
      "\n",
      "    Full relationships:\n",
      "    - Full relationships appear in dedicated relationship files, often having a filename that references two entities\n",
      "    - Full relationships typically have references to a source and destination node.\n",
      "    - Full relationships _do not have_ unique identifiers, but instead have references to the primary keys of the source and destination nodes.\n",
      "    - The absence of a single, unique identifier is a strong indicator that a file is a full relationship.\n",
      "\n",
      "    Reference relationships:\n",
      "    - Reference relationships appear as foreign key references in node files\n",
      "    - Reference relationship foreign key column names often hint at the destination node and relationship type\n",
      "    - References may be hierarchical container relationships, with terminology revealing parent-child, \"has\", \"contains\", membership, or similar relationship\n",
      "    - References may be peer relationships, that is often a self-reference to a similar class of nodes. For example, \"knows\" or \"see also\"\n",
      "\n",
      "    The resulting schema should be a connected graph, with no isolated components.\n",
      "\n",
      "\n",
      "    Prepare for the task:\n",
      "    - get the user goal using the 'get_approved_user_goal' tool\n",
      "    - get the list of approved files using the 'get_approved_files' tool\n",
      "    - get the current construction plan using the 'get_proposed_construction_plan' tool\n",
      "\n",
      "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
      "    1. For each approved file, consider whether it represents a node or relationship. Check the content for potential unique identifiers using the 'sample_file' tool.\n",
      "    2. For each identifier, verify that it is unique by using the 'search_file' tool.\n",
      "    3. Use the node vs relationship guidance for deciding whether the file represents a node or a relationship.\n",
      "    4. For a node file, propose a node construction using the 'propose_node_construction' tool. \n",
      "    5. If the node contains a reference relationship, use the 'propose_relationship_construction' tool to propose a relationship construction. \n",
      "    6. For a relationship file, propose a relationship construction using the 'propose_relationship_construction' tool\n",
      "    7. If you need to remove a construction, use the 'remove_node_construction' or 'remove_relationship_construction' tool\n",
      "    8. When you are done with construction proposals, use the 'get_proposed_construction_plan' tool to present the plan to the user\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# finally, combine all the prompt parts together\n",
    "proposal_agent_instruction = f\"\"\"\n",
    "{proposal_agent_role_and_goal}\n",
    "{proposal_agent_hints}\n",
    "{proposal_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(proposal_agent_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc04db",
   "metadata": {},
   "source": [
    "## 6.4. Tool Definitions for Schema Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6201bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools defined in previous notebook\n",
    "from tools import get_approved_user_goal, get_approved_files, sample_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28da6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_neo4j_import_dir\n",
    "\n",
    "SEARCH_RESULTS = \"search_results\"\n",
    "\n",
    "# A simple grep-like tool for searching text files\n",
    "def search_file(file_path: str, query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Searches any text file (markdown, csv, txt) for lines containing the given query string.\n",
    "    Simple grep-like functionality that works with any text file.\n",
    "    Search is always case insensitive.\n",
    "\n",
    "    Args:\n",
    "      file_path: Path to the file, relative to the Neo4j import directory.\n",
    "      query: The string to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'status' ('success' or 'error').\n",
    "              If 'success', includes 'search_results' containing 'matching_lines'\n",
    "              (a list of dictionaries with 'line_number' and 'content' keys)\n",
    "              and basic metadata about the search.\n",
    "              If 'error', includes an 'error_message'.\n",
    "    \"\"\"\n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "    p = import_dir / file_path\n",
    "\n",
    "    if not p.exists():\n",
    "        return tool_error(f\"File does not exist: {file_path}\")\n",
    "    if not p.is_file():\n",
    "        return tool_error(f\"Path is not a file: {file_path}\")\n",
    "\n",
    "    # Handle empty query - return no results\n",
    "    if not query:\n",
    "        return tool_success(SEARCH_RESULTS, {\n",
    "            \"metadata\": {\n",
    "                \"path\": file_path,\n",
    "                \"query\": query,\n",
    "                \"lines_found\": 0\n",
    "            },\n",
    "            \"matching_lines\": []\n",
    "        })\n",
    "\n",
    "    matching_lines = []\n",
    "    search_query = query.lower()\n",
    "    \n",
    "    try:\n",
    "        with open(p, 'r', encoding='utf-8') as file:\n",
    "            # Process the file line by line\n",
    "            for i, line in enumerate(file, 1):\n",
    "                line_to_check = line.lower()\n",
    "                if search_query in line_to_check:\n",
    "                    matching_lines.append({\n",
    "                        \"line_number\": i,\n",
    "                        \"content\": line.strip()  # Remove trailing newlines\n",
    "                    })\n",
    "                        \n",
    "    except Exception as e:\n",
    "        return tool_error(f\"Error reading or searching file {file_path}: {e}\")\n",
    "\n",
    "    # Prepare basic metadata\n",
    "    metadata = {\n",
    "        \"path\": file_path,\n",
    "        \"query\": query,\n",
    "        \"lines_found\": len(matching_lines)\n",
    "    }\n",
    "    \n",
    "    result_data = {\n",
    "        \"metadata\": metadata,\n",
    "        \"matching_lines\": matching_lines\n",
    "    }\n",
    "    return tool_success(SEARCH_RESULTS, result_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fb3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tool: Propose Node Construction\n",
    "\n",
    "PROPOSED_CONSTRUCTION_PLAN = \"proposed_construction_plan\"\n",
    "NODE_CONSTRUCTION = \"node_construction\"\n",
    "\n",
    "def propose_node_construction(approved_file: str, proposed_label: str, unique_column_name: str, proposed_properties: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Propose a node construction for an approved file that supports the user goal.\n",
    "\n",
    "    The construction will be added to the proposed construction plan dictionary under using proposed_label as the key.\n",
    "\n",
    "    The construction entry will be a dictionary with the following keys:\n",
    "    - construction_type: \"node\"\n",
    "    - source_file: the approved file to propose a node construction for\n",
    "    - label: the proposed label of the node\n",
    "    - unique_column_name: the name of the column that will be used to uniquely identify constructed nodes\n",
    "    - properties: A list of property names for the node, derived from column names in the approved file\n",
    "\n",
    "    Args:\n",
    "        approved_file: The approved file to propose a node construction for\n",
    "        proposed_label: The proposed label for constructed nodes (used as key in the construction plan)\n",
    "        unique_column_name: The name of the column that will be used to uniquely identify constructed nodes\n",
    "        proposed_properties: column names that should be imported as node properties\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a \"node_construction\" key with the construction plan for the node\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # quick sanity check -- does the approved file have the unique column?\n",
    "    search_results = search_file(approved_file, unique_column_name)\n",
    "    if search_results[\"status\"] == \"error\":\n",
    "        return search_results # return the error\n",
    "    if search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the column {unique_column_name}. Check the file content and try again.\")\n",
    "\n",
    "    # get the current construction plan, or an empty one if none exists\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    node_construction_rule = {\n",
    "        \"construction_type\": \"node\",\n",
    "        \"source_file\": approved_file,\n",
    "        \"label\": proposed_label,\n",
    "        \"unique_column_name\": unique_column_name,\n",
    "        \"properties\": proposed_properties\n",
    "    }   \n",
    "    construction_plan[proposed_label] = node_construction_rule\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(NODE_CONSTRUCTION, node_construction_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a686771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIONSHIP_CONSTRUCTION = \"relationship_construction\"\n",
    "\n",
    "def propose_relationship_construction(approved_file: str, proposed_relationship_type: str, \n",
    "    from_node_label: str,from_node_column: str, to_node_label:str, to_node_column: str, \n",
    "    proposed_properties: list[str], \n",
    "    tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Propose a relationship construction for an approved file that supports the user goal.\n",
    "\n",
    "    The construction will be added to the proposed construction plan dictionary under using proposed_relationship_type as the key.\n",
    "\n",
    "    Args:\n",
    "        approved_file: The approved file to propose a node construction for\n",
    "        proposed_relationship_type: The proposed label for constructed relationships\n",
    "        from_node_label: The label of the source node\n",
    "        from_node_column: The name of the column within the approved file that will be used to uniquely identify source nodes\n",
    "        to_node_label: The label of the target node\n",
    "        to_node_column: The name of the column within the approved file that will be used to uniquely identify target nodes\n",
    "        unique_column_name: The name of the column that will be used to uniquely identify target nodes\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a \"relationship_construction\" key with the construction plan for the node\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # quick sanity check -- does the approved file have the from_node_column?\n",
    "    search_results = search_file(approved_file, from_node_column)\n",
    "    if search_results[\"status\"] == \"error\": \n",
    "        return search_results  # return the error if there is one\n",
    "    if search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the from node column {from_node_column}. Check the content of the file and reconsider the relationship.\")\n",
    "\n",
    "    # quick sanity check -- does the approved file have the to_node_column?\n",
    "    search_results = search_file(approved_file, to_node_column)\n",
    "    if search_results[\"status\"] == \"error\" or search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the to node column {to_node_column}. Check the content of the file and reconsider the relationship.\")\n",
    "\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    relationship_construction_rule = {\n",
    "        \"construction_type\": \"relationship\",\n",
    "        \"source_file\": approved_file,\n",
    "        \"relationship_type\": proposed_relationship_type,\n",
    "        \"from_node_label\": from_node_label,\n",
    "        \"from_node_column\": from_node_column,\n",
    "        \"to_node_label\": to_node_label,\n",
    "        \"to_node_column\": to_node_column,\n",
    "        \"properties\": proposed_properties\n",
    "    }   \n",
    "    construction_plan[proposed_relationship_type] = relationship_construction_rule\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(RELATIONSHIP_CONSTRUCTION, relationship_construction_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Remove Node Construction\n",
    "def remove_node_construction(node_label: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Remove a node construction from the proposed construction plan based on label.\n",
    "\n",
    "    Args:\n",
    "        node_label: The label of the node construction to remove\n",
    "        tool_context: The tool context\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a 'node_construction_removed' key with the label of the removed node construction\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    if node_label not in construction_plan:\n",
    "        return tool_success(key=\"node_construction_not_removed\",result=\"node construction rule not found. removal not needed.\")\n",
    "\n",
    "    del construction_plan[node_label]\n",
    "\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(\"node_construction_removed\", node_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3aae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Remove Relationship Construction\n",
    "def remove_relationship_construction(relationship_type: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Remove a relationship construction from the proposed construction plan based on type.\n",
    "\n",
    "    Args:\n",
    "        relationship_type: The type of the relationship construction to remove\n",
    "        tool_context: The tool context\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a 'relationship_construction_removed' key with the type of the removed relationship construction\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "\n",
    "    if relationship_type not in construction_plan:\n",
    "        return tool_success(\"relationship_construction_not_removed\",\"relationship construction rule not found. removal not needed.\")\n",
    "    \n",
    "    construction_plan.pop(relationship_type)\n",
    "    \n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(\"relationship_construction_removed\", relationship_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32b41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Get Proposed construction Plan\n",
    "\n",
    "def get_proposed_construction_plan(noop: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed construction plan, a dictionary of construction rules.\n",
    "    Args:\n",
    "        noop: no op parameter\n",
    "    \"\"\"\n",
    "    return tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c207f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Approve the proposed construction plan\n",
    "\n",
    "APPROVED_CONSTRUCTION_PLAN = \"approved_construction_plan\"\n",
    "\n",
    "def approve_proposed_construction_plan(noop: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Approve the proposed construction plan, if there is one.\n",
    "    Args:\n",
    "        noop: no op parameter\n",
    "    \"\"\"\n",
    "    if not PROPOSED_CONSTRUCTION_PLAN in tool_context.state:\n",
    "        return tool_error(\"No proposed construction plan found. Propose a plan first.\")\n",
    "    \n",
    "    tool_context.state[APPROVED_CONSTRUCTION_PLAN] = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN)\n",
    "    return tool_success(APPROVED_CONSTRUCTION_PLAN, tool_context.state[APPROVED_CONSTRUCTION_PLAN])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3418eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools for the structured schema proposal agent\n",
    "structured_schema_proposal_agent_tools = [\n",
    "    get_approved_user_goal, \n",
    "    get_approved_files, \n",
    "    get_proposed_construction_plan,\n",
    "    sample_file, \n",
    "    search_file,\n",
    "    propose_node_construction,\n",
    "    propose_relationship_construction, \n",
    "    remove_node_construction, \n",
    "    remove_relationship_construction\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a5944",
   "metadata": {},
   "source": [
    "## 6.5. Define the Agent for Schema Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a069d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents.callback_context import CallbackContext\n",
    "\n",
    "# a helper function to log the agent name during execution\n",
    "def log_agent(callback_context: CallbackContext) -> None:\n",
    "    print(f\"\\n### Entering Agent: {callback_context.agent_name}\")\n",
    "\n",
    "SCHEMA_AGENT_NAME = \"schema_proposal_agent_v1\"\n",
    "schema_proposal_agent = LlmAgent(\n",
    "    name=SCHEMA_AGENT_NAME,\n",
    "    description=\"Proposes a knowledge graph schema based on the user goal and approved file list\",\n",
    "    model=llm,\n",
    "    instruction=proposal_agent_instruction,\n",
    "    tools=structured_schema_proposal_agent_tools,\n",
    "    before_agent_callback=log_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72812c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "# notice the initial state being passed in here to simulate previous workflow steps\n",
    "schema_proposal_caller = await make_agent_caller(schema_proposal_agent, {\n",
    "    \"feedback\": \"\",\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        'assemblies.csv', \n",
    "        'parts.csv', \n",
    "        'part_supplier_mapping.csv', \n",
    "        'products.csv', \n",
    "        'suppliers.csv'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff9ddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: How can these files be imported to construct the knowledge graph?\n",
      "\n",
      "### Entering Agent: schema_proposal_agent_v1\n",
      "Current step: 1\n",
      "Current step: 2\n",
      "Current step: 3\n",
      "Current step: 4\n",
      "Current step: 5\n",
      "Current step: 6\n",
      "Current step: 7\n",
      "Current step: 8\n",
      "Current step: 9\n",
      "<<< Agent Response: The knowledge graph construction plan is now defined with the following nodes and relationships:\n",
      "\n",
      "### Nodes:\n",
      "1. **Assembly Node**:\n",
      "   - **Label**: Assembly\n",
      "   - **Unique Identifier**: `assembly_id`\n",
      "   - **Properties**: `assembly_name`, `quantity`, `product_id`\n",
      "\n",
      "2. **Part Node**:\n",
      "   - **Label**: Part\n",
      "   - **Unique Identifier**: `part_id`\n",
      "   - **Properties**: `part_name`, `quantity`, `assembly_id`\n",
      "\n",
      "3. **Product Node**:\n",
      "   - **Label**: Product\n",
      "   - **Unique Identifier**: `product_id`\n",
      "   - **Properties**: `product_name`, `price`, `description`\n",
      "\n",
      "4. **Supplier Node**:\n",
      "   - **Label**: Supplier\n",
      "   - **Unique Identifier**: `supplier_id`\n",
      "   - **Properties**: `name`, `specialty`, `city`, `country`, `website`, `contact_email`\n",
      "\n",
      "### Relationships:\n",
      "1. **Supplies Relationship**:\n",
      "   - **Type**: Supplies\n",
      "   - **From Node (Supplier)**: Identified by `supplier_id`\n",
      "   - **To Node (Part)**: Identified by `part_id`\n",
      "   - **Properties**: `part_name`, `lead_time_days`, `unit_cost`, `minimum_order_quantity`, `preferred_supplier`\n",
      "\n",
      "This schema will provide a robust framework for performing supply chain analysis and root cause detection in a multi-level configuration of products, assemblies, parts, and suppliers. If you need further adjustments or enhancements, feel free to ask!\n",
      "\n",
      "---\n",
      "\n",
      "Session state:  {'feedback': '', 'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis..'}, 'approved_files': ['assemblies.csv', 'parts.csv', 'part_supplier_mapping.csv', 'products.csv', 'suppliers.csv'], 'proposed_construction_plan': {'Assembly': {'construction_type': 'node', 'source_file': 'assemblies.csv', 'label': 'Assembly', 'unique_column_name': 'assembly_id', 'properties': ['assembly_name', 'quantity', 'product_id']}, 'Part': {'construction_type': 'node', 'source_file': 'parts.csv', 'label': 'Part', 'unique_column_name': 'part_id', 'properties': ['part_name', 'quantity', 'assembly_id']}, 'Product': {'construction_type': 'node', 'source_file': 'products.csv', 'label': 'Product', 'unique_column_name': 'product_id', 'properties': ['product_name', 'price', 'description']}, 'Supplier': {'construction_type': 'node', 'source_file': 'suppliers.csv', 'label': 'Supplier', 'unique_column_name': 'supplier_id', 'properties': ['name', 'specialty', 'city', 'country', 'website', 'contact_email']}, 'Supplies': {'construction_type': 'relationship', 'source_file': 'part_supplier_mapping.csv', 'relationship_type': 'Supplies', 'from_node_label': 'Supplier', 'from_node_column': 'supplier_id', 'to_node_label': 'Part', 'to_node_column': 'part_id', 'properties': ['part_name', 'lead_time_days', 'unit_cost', 'minimum_order_quantity', 'preferred_supplier']}}}\n",
      "Proposed construction plan:  {'Assembly': {'construction_type': 'node', 'source_file': 'assemblies.csv', 'label': 'Assembly', 'unique_column_name': 'assembly_id', 'properties': ['assembly_name', 'quantity', 'product_id']}, 'Part': {'construction_type': 'node', 'source_file': 'parts.csv', 'label': 'Part', 'unique_column_name': 'part_id', 'properties': ['part_name', 'quantity', 'assembly_id']}, 'Product': {'construction_type': 'node', 'source_file': 'products.csv', 'label': 'Product', 'unique_column_name': 'product_id', 'properties': ['product_name', 'price', 'description']}, 'Supplier': {'construction_type': 'node', 'source_file': 'suppliers.csv', 'label': 'Supplier', 'unique_column_name': 'supplier_id', 'properties': ['name', 'specialty', 'city', 'country', 'website', 'contact_email']}, 'Supplies': {'construction_type': 'relationship', 'source_file': 'part_supplier_mapping.csv', 'relationship_type': 'Supplies', 'from_node_label': 'Supplier', 'from_node_column': 'supplier_id', 'to_node_label': 'Part', 'to_node_column': 'part_id', 'properties': ['part_name', 'lead_time_days', 'unit_cost', 'minimum_order_quantity', 'preferred_supplier']}}\n"
     ]
    }
   ],
   "source": [
    "await schema_proposal_caller.call(\"How can these files be imported to construct the knowledge graph?\")\n",
    "\n",
    "session_end = await schema_proposal_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "\n",
    "if 'proposed_construction_plan' in session_end.state:\n",
    "    print(\"Proposed construction plan: \", session_end.state['proposed_construction_plan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75119cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "await schema_proposal_caller.call(\"How can these files be imported to construct the knowledge graph?\")\n",
    "\n",
    "session_end = await schema_proposal_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "\n",
    "if 'proposed_construction_plan' in session_end.state:\n",
    "    print(\"Proposed construction plan: \", session_end.state['proposed_construction_plan'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2b9c0",
   "metadata": {},
   "source": [
    "## 6.6. Agent Instructions for Schema Critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4edb8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph modeling with property graphs. \n",
    "    Criticize the proposed schema for relevance to the user goal and approved files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db40359",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_hints = \"\"\"\n",
    "    Criticize the proposed schema for relevance and correctness:\n",
    "    - Are unique identifiers actually unique? Use the 'search_file' tool to validate. Composite identifier are not acceptable.\n",
    "    - Could any nodes be relationships instead? Double-check that unique identifiers are unique and not references to other nodes. Use the 'search_file' tool to validate\n",
    "    - Can you manually trace through the source data to find the necessary information for anwering a hypothetical question?\n",
    "    - Is every node in the schema connected? What relationships could be missing? Every node should connect to at least one other node.\n",
    "    - Are hierarchical container relationships missing? \n",
    "    - Are any relationships redundant? A relationship between two nodes is redundant if it is semantically equivalent to or the inverse of another relationship between those two nodes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e32c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - get the user goal using the 'get_approved_user_goal' tool\n",
    "    - get the list of approved files using the 'get_approved_files' tool\n",
    "    - get the construction plan using the 'get_proposed_construction_plan' tool\n",
    "    - use the 'sample_file' and 'search_file' tools to validate the schema design\n",
    "\n",
    "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
    "    1. Analyze each construction rule in the proposed construction plan.\n",
    "    2. Use tools to validate the construction rules for relevance and correctness.\n",
    "    3. If the schema looks good, respond with a one word reply: 'valid'.\n",
    "    4. If the schema has problems, respond with 'retry' and provide feedback as a concise bullet list of problems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46b40903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    You are an expert at knowledge graph modeling with property graphs. \n",
      "    Criticize the proposed schema for relevance to the user goal and approved files.\n",
      "\n",
      "\n",
      "    Criticize the proposed schema for relevance and correctness:\n",
      "    - Are unique identifiers actually unique? Use the 'search_file' tool to validate. Composite identifier are not acceptable.\n",
      "    - Could any nodes be relationships instead? Double-check that unique identifiers are unique and not references to other nodes. Use the 'search_file' tool to validate\n",
      "    - Can you manually trace through the source data to find the necessary information for anwering a hypothetical question?\n",
      "    - Is every node in the schema connected? What relationships could be missing? Every node should connect to at least one other node.\n",
      "    - Are hierarchical container relationships missing? \n",
      "    - Are any relationships redundant? A relationship between two nodes is redundant if it is semantically equivalent to or the inverse of another relationship between those two nodes.\n",
      "\n",
      "\n",
      "    Prepare for the task:\n",
      "    - get the user goal using the 'get_approved_user_goal' tool\n",
      "    - get the list of approved files using the 'get_approved_files' tool\n",
      "    - get the construction plan using the 'get_proposed_construction_plan' tool\n",
      "    - use the 'sample_file' and 'search_file' tools to validate the schema design\n",
      "\n",
      "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
      "    1. Analyze each construction rule in the proposed construction plan.\n",
      "    2. Use tools to validate the construction rules for relevance and correctness.\n",
      "    3. If the schema looks good, respond with a one word reply: 'valid'.\n",
      "    4. If the schema has problems, respond with 'retry' and provide feedback as a concise bullet list of problems.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine all the prompt parts together\n",
    "critic_agent_instruction = f\"\"\"\n",
    "{critic_agent_role_and_goal}\n",
    "{critic_agent_hints}\n",
    "{critic_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(critic_agent_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe8de3",
   "metadata": {},
   "source": [
    "## 6.7. Tool Definitions for Schema Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54b0ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_critic_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files,\n",
    "    get_proposed_construction_plan,\n",
    "    sample_file, search_file\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "CRITIC_NAME = \"schema_critic_agent_v1\"\n",
    "CALLING_CRITIC_RESULT_STATE_KEY = \"feedback\"\n",
    "schema_critic_agent = LlmAgent(\n",
    "    name=CRITIC_NAME,\n",
    "    description=\"Criticizes the proposed schema for relevance to the user goal and approved files.\",\n",
    "    model=llm,\n",
    "    instruction=critic_agent_instruction,\n",
    "    tools=schema_critic_agent_tools,\n",
    "    output_key=CALLING_CRITIC_RESULT_STATE_KEY,# specify the context state key which will contain the result of calling the critic,\n",
    "    before_agent_callback=log_agent\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b669a",
   "metadata": {},
   "source": [
    "## 6.9. Define the refinement loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c153fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.adk.agents.base_agent import BaseAgent\n",
    "from google.adk.events import Event, EventActions\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "class CheckStatusAndEscalate(BaseAgent):\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        feedback = ctx.session.state.get(\"feedback\", \"valid\")\n",
    "        should_stop = (feedback == \"valid\")\n",
    "        yield Event(author=self.name, actions=EventActions(escalate=should_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6721b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_refinement_loop = LoopAgent(\n",
    "    name=\"schema_refinement_loop\",\n",
    "    description=\"Analyzes approved files to propose a schema based on user intent and feedback\",\n",
    "    max_iterations=2,\n",
    "    sub_agents=[schema_proposal_agent, schema_critic_agent, CheckStatusAndEscalate(name=\"StopChecker\")],\n",
    "    before_agent_callback=log_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2172cb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: How can these files be imported?\n",
      "\n",
      "### Entering Agent: schema_refinement_loop\n",
      "\n",
      "### Entering Agent: schema_proposal_agent_v1\n",
      "Current step: 1\n",
      "Current step: 2\n",
      "Current step: 3\n",
      "Current step: 4\n",
      "Current step: 5\n",
      "Current step: 6\n",
      "Current step: 7\n",
      "Current step: 8\n",
      "Current step: 9\n",
      "Current step: 10\n",
      "Current step: 11\n",
      "Current step: 12\n",
      "Current step: 13\n",
      "\n",
      "### Entering Agent: schema_critic_agent_v1\n",
      "Current step: 14\n",
      "Current step: 15\n",
      "Current step: 16\n",
      "Current step: 17\n",
      "\n",
      "### Entering Agent: schema_proposal_agent_v1\n",
      "Current step: 18\n",
      "\n",
      "### Entering Agent: schema_critic_agent_v1\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o in organization org-1HzOSaHXUQKYaPFLy3uSUl8E on tokens per min (TPM): Limit 30000, Used 24685, Requested 7842. Please try again in 5.054s. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/llms/openai/openai.py:812\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, messages, optional_params, litellm_params, provider_config, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream)\u001b[39m\n\u001b[32m    799\u001b[39m logging_obj.pre_call(\n\u001b[32m    800\u001b[39m     \u001b[38;5;28minput\u001b[39m=data[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    801\u001b[39m     api_key=openai_aclient.api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    809\u001b[39m     },\n\u001b[32m    810\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m headers, response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_openai_chat_completion_request(\n\u001b[32m    813\u001b[39m     openai_aclient=openai_aclient,\n\u001b[32m    814\u001b[39m     data=data,\n\u001b[32m    815\u001b[39m     timeout=timeout,\n\u001b[32m    816\u001b[39m     logging_obj=logging_obj,\n\u001b[32m    817\u001b[39m )\n\u001b[32m    818\u001b[39m stringified_response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py:190\u001b[39m, in \u001b[36mtrack_llm_api_timing.<locals>.decorator.<locals>.async_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/llms/openai/openai.py:447\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/llms/openai/openai.py:429\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    428\u001b[39m     raw_response = (\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m openai_aclient.chat.completions.with_raw_response.create(\n\u001b[32m    430\u001b[39m             **data, timeout=timeout\n\u001b[32m    431\u001b[39m         )\n\u001b[32m    432\u001b[39m     )\n\u001b[32m    433\u001b[39m     end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/openai/_legacy_response.py:381\u001b[39m, in \u001b[36masync_to_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:2583\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2582\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2584\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2585\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2586\u001b[39m         {\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2588\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2589\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2590\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2591\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2592\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2593\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2594\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2595\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2596\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2597\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2598\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2599\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2600\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2601\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2602\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2603\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2604\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2605\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2606\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2607\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2608\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2609\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2612\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2613\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2614\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2615\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2616\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2617\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2619\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2620\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2621\u001b[39m         },\n\u001b[32m   2622\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2623\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2625\u001b[39m     ),\n\u001b[32m   2626\u001b[39m     options=make_request_options(\n\u001b[32m   2627\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2628\u001b[39m     ),\n\u001b[32m   2629\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2630\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2631\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2632\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1791\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1594\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1593\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1HzOSaHXUQKYaPFLy3uSUl8E on tokens per min (TPM): Limit 30000, Used 24685, Requested 7842. Please try again in 5.054s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/main.py:543\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m asyncio.iscoroutine(init_response):\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m init_response\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/llms/openai/openai.py:859\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, messages, optional_params, litellm_params, provider_config, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream)\u001b[39m\n\u001b[32m    857\u001b[39m message = \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    860\u001b[39m     status_code=status_code,\n\u001b[32m    861\u001b[39m     message=message,\n\u001b[32m    862\u001b[39m     headers=error_headers,\n\u001b[32m    863\u001b[39m     body=exception_body,\n\u001b[32m    864\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1HzOSaHXUQKYaPFLy3uSUl8E on tokens per min (TPM): Limit 30000, Used 24685, Requested 7842. Please try again in 5.054s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# NOTE: this may take some time to run, and may require further iterations to satisfy the critic!\u001b[39;00m\n\u001b[32m      4\u001b[39m refinement_loop_caller = \u001b[38;5;28;01mawait\u001b[39;00m make_agent_caller(schema_refinement_loop, {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeedback\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapproved_user_goal\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     ]\n\u001b[32m     17\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m refinement_loop_caller.call(\u001b[33m\"\u001b[39m\u001b[33mHow can these files be imported?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Alternatively, you can uncomment the line below to run the refinement loop with verbose output\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# await refinement_loop_caller.call(\"How can these files be imported?\", True)\u001b[39;00m\n\u001b[32m     24\u001b[39m session_end = \u001b[38;5;28;01mawait\u001b[39;00m refinement_loop_caller.get_session()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL_PROJECTS/AGENTIC-KG/helper.py:57\u001b[39m, in \u001b[36mAgentCaller.call\u001b[39m\u001b[34m(self, query, verbose, max_steps)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Key Concept: run_async executes the agent logic and yields Events.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# We iterate through events to find the final answer.\u001b[39;00m\n\u001b[32m     56\u001b[39m step = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.runner.run_async(user_id=\u001b[38;5;28mself\u001b[39m.user_id, session_id=\u001b[38;5;28mself\u001b[39m.session_id, new_message=content):\n\u001b[32m     58\u001b[39m     \u001b[38;5;66;03m# You can uncomment the line below to see *all* events during execution\u001b[39;00m\n\u001b[32m     59\u001b[39m     step += \u001b[32m1\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/runners.py:248\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    245\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/runners.py:244\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message)\u001b[39m\n\u001b[32m    239\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(invocation_context, session, execute)\n\u001b[32m    243\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/runners.py:288\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    286\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    287\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    289\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    290\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session_service.append_event(\n\u001b[32m    291\u001b[39m             session=session, event=event\n\u001b[32m    292\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/runners.py:238\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    239\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/base_agent.py:248\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    245\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/base_agent.py:238\u001b[39m, in \u001b[36mBaseAgent.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    235\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/loop_agent.py:63\u001b[39m, in \u001b[36mLoopAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     61\u001b[39m should_exit = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(sub_agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.actions.escalate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/base_agent.py:248\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    245\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/base_agent.py:238\u001b[39m, in \u001b[36mBaseAgent.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    235\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/agents/llm_agent.py:288\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async_impl\u001b[39m(\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: InvocationContext\n\u001b[32m    286\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    287\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    289\u001b[39m       \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    290\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:401\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    399\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    402\u001b[39m     last_event = event\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:437\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    426\u001b[39m model_response_event = Event(\n\u001b[32m    427\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    428\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    429\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    430\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    431\u001b[39m )\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    434\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    435\u001b[39m     )\n\u001b[32m    436\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    440\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    441\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m         )\n\u001b[32m    446\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    447\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:761\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    758\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:745\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    732\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    733\u001b[39m     llm_request,\n\u001b[32m    734\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    735\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    736\u001b[39m )\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    739\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    743\u001b[39m     )\n\u001b[32m    744\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    746\u001b[39m     trace_call_llm(\n\u001b[32m    747\u001b[39m         invocation_context,\n\u001b[32m    748\u001b[39m         model_response_event.id,\n\u001b[32m    749\u001b[39m         llm_request,\n\u001b[32m    750\u001b[39m         llm_response,\n\u001b[32m    751\u001b[39m     )\n\u001b[32m    752\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:937\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    935\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:921\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    920\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    922\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/models/lite_llm.py:855\u001b[39m, in \u001b[36mLiteLlm.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    852\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m aggregated_llm_response_with_tool_call\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_client.acompletion(**completion_args)\n\u001b[32m    856\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m _model_response_to_generate_content_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/google/adk/models/lite_llm.py:105\u001b[39m, in \u001b[36mLiteLLMClient.acompletion\u001b[39m\u001b[34m(self, model, messages, tools, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macompletion\u001b[39m(\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m, model, messages, tools, **kwargs\n\u001b[32m     92\u001b[39m ) -> Union[ModelResponse, CustomStreamWrapper]:\n\u001b[32m     93\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Asynchronously calls acompletion.\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m    The model response as a message.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m acompletion(\n\u001b[32m    106\u001b[39m       model=model,\n\u001b[32m    107\u001b[39m       messages=messages,\n\u001b[32m    108\u001b[39m       tools=tools,\n\u001b[32m    109\u001b[39m       **kwargs,\n\u001b[32m    110\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/utils.py:1598\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1596\u001b[39m timeout = _get_wrapper_timeout(kwargs=kwargs, exception=e)\n\u001b[32m   1597\u001b[39m \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1598\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/utils.py:1449\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1446\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1448\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1449\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m original_function(*args, **kwargs)\n\u001b[32m   1450\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1452\u001b[39m     kwargs=kwargs,\n\u001b[32m   1453\u001b[39m     call_type=call_type,\n\u001b[32m   1454\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/main.py:562\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, **kwargs)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    561\u001b[39m     custom_llm_provider = custom_llm_provider \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:329\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ExceptionCheckers.is_error_str_rate_limit(error_str):\n\u001b[32m    328\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[32m    330\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    331\u001b[39m         model=model,\n\u001b[32m    332\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    333\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    334\u001b[39m     )\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ExceptionCheckers.is_error_str_context_window_exceeded(error_str):\n\u001b[32m    336\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o in organization org-1HzOSaHXUQKYaPFLy3uSUl8E on tokens per min (TPM): Limit 30000, Used 24685, Requested 7842. Please try again in 5.054s. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "# NOTE: this may take some time to run, and may require further iterations to satisfy the critic!\n",
    "refinement_loop_caller = await make_agent_caller(schema_refinement_loop, {\n",
    "    \"feedback\": \"\",\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        'products.csv', \n",
    "        'assemblies.csv', \n",
    "        'parts.csv', \n",
    "        'part_supplier_mapping.csv', \n",
    "        'suppliers.csv'\n",
    "    ]\n",
    "})\n",
    "\n",
    "await refinement_loop_caller.call(\"How can these files be imported?\")\n",
    "\n",
    "# Alternatively, you can uncomment the line below to run the refinement loop with verbose output\n",
    "# await refinement_loop_caller.call(\"How can these files be imported?\", True)\n",
    "\n",
    "session_end = await refinement_loop_caller.get_session()\n",
    "print(\"Session state: \", session_end.state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef815d",
   "metadata": {},
   "source": [
    "## 6.12. Extra - Create the top-level agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0548d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9271ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools import agent_tool\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "\n",
    "\n",
    "schema_proposal_coordinator_instruction = \"\"\"\n",
    "    You are a coordinator for the schema proposal process. Use tools to propose a schema to the user.\n",
    "    If the user disapproves, use the tools to refine the schema and ask the user to approve again.\n",
    "    If the user approves, use the 'approve_proposed_schema' tool to record the approval.\n",
    "    When the schema approval has been recorded, use the 'finished' tool.\n",
    "\n",
    "    Guidance for tool use:\n",
    "    - Use the 'schema_refinement_loop' tool to produce or update a proposed schema with construction rules. \n",
    "    - Use the 'get_proposed_schema' tool to get the proposed schema\n",
    "    - Use the 'get_proposed_construction_plan' tool to get the construction rules for transforming approved files into the schema\n",
    "    - Present the proposed schema and construction rules to the user for approval\n",
    "    - If they disapprove, consider their feedback and go back to step 1\n",
    "    - If the user approves, use the 'approve_proposed_schema' tool and the 'approve_proposed_construction_plan' tool to record the approval\n",
    "\"\"\"\n",
    "\n",
    "refinement_loop_as_tool = agent_tool.AgentTool(schema_refinement_loop)\n",
    "\n",
    "\n",
    "# initialize context with blank feedback, which may get filled later by the schema_critic_agent\n",
    "def initialize_feedback(callback_context: CallbackContext) -> None:\n",
    "    callback_context.state[\"feedback\"] = \"\"\n",
    "\n",
    "schema_proposal_coordinator = LlmAgent(\n",
    "    name=\"schema_proposal_coordinator\",\n",
    "    model=llm,\n",
    "    instruction=schema_proposal_coordinator_instruction,\n",
    "    tools=[\n",
    "        refinement_loop_as_tool, \n",
    "        get_proposed_construction_plan, \n",
    "        approve_proposed_construction_plan\n",
    "    ], \n",
    "    before_agent_callback=initialize_feedback\n",
    ")\n",
    "\n",
    "structured_schema_proposal_caller = await make_agent_caller(schema_proposal_coordinator, {\n",
    "    \"feedback\": \"\",\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        'assemblies.csv', \n",
    "        'parts.csv', \n",
    "        'part_supplier_mapping.csv', \n",
    "        'products.csv', \n",
    "        'suppliers.csv'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Run the Initial Conversation\n",
    "await structured_schema_proposal_caller.call(\"How can these files be imported?\")\n",
    "\n",
    "session_end = await structured_schema_proposal_caller.get_session()\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "# Agree with the file suggestions\n",
    "await structured_schema_proposal_caller.call(\"Yes, let's do it!\", True)\n",
    "\n",
    "session_end = await structured_schema_proposal_caller.get_session()\n",
    "\n",
    "print(\"Approved construction plan: \", session_end.state['approved_user_goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720aa30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9abdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d748511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-kg-iRiaRh-y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
