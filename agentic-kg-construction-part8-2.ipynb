{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8efd5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c097d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CHVPZKEaRZxgZo7MG3Bn3kEfNsMzB', created=1758288357, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready. How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3445924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be957a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'query_result': [{'nonEntityLabels': ['Assembly']},\n",
       "  {'nonEntityLabels': ['Part']},\n",
       "  {'nonEntityLabels': ['Product']},\n",
       "  {'nonEntityLabels': ['Supplier']}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import load_product_nodes\n",
    "\n",
    "load_product_nodes()\n",
    "\n",
    "# expect to find non-entity nodes with a \"Product\" label\n",
    "graphdb.send_query(\"MATCH (n) WHERE NOT n:`__Entity__` return DISTINCT labels(n) as nonEntityLabels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928d7c6",
   "metadata": {},
   "source": [
    "## 8.2.3 Initialize State from Previous Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6464c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the approved construction plan should look something like this...\n",
    "approved_construction_plan = {\n",
    "    \"Assembly\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"label\": \"Assembly\", \n",
    "        \"unique_column_name\": \"assembly_id\", \n",
    "        \"properties\": [\"assembly_name\", \"quantity\", \"product_id\"]\n",
    "    }, \n",
    "    \"Part\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"label\": \"Part\", \n",
    "        \"unique_column_name\": \"part_id\", \n",
    "        \"properties\": [\"part_name\", \"quantity\", \"assembly_id\"]\n",
    "    }, \n",
    "    \"Product\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"products.csv\", \n",
    "        \"label\": \"Product\", \n",
    "        \"unique_column_name\": \"product_id\", \n",
    "        \"properties\": [\"product_name\", \"price\", \"description\"]\n",
    "    }, \n",
    "    \"Supplier\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"suppliers.csv\", \n",
    "        \"label\": \"Supplier\", \n",
    "        \"unique_column_name\": \"supplier_id\", \n",
    "        \"properties\": [\"name\", \"specialty\", \"city\", \"country\", \"website\", \"contact_email\"]\n",
    "    }, \n",
    "    \"Contains\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"relationship_type\": \"Contains\", \n",
    "        \"from_node_label\": \"Product\", \n",
    "        \"from_node_column\": \"product_id\", \n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\", \n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Is_Part_Of\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"relationship_type\": \"Is_Part_Of\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\", \n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Supplied_By\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"part_supplier_mapping.csv\", \n",
    "        \"relationship_type\": \"Supplied_By\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Supplier\", \n",
    "        \"to_node_column\": \"supplier_id\", \n",
    "        \"properties\": [\"supplier_name\", \"lead_time_days\", \"unit_cost\", \"minimum_order_quantity\", \"preferred_supplier\"]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12b3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_files = [\n",
    "    \"product_reviews/gothenburg_table_reviews.md\",\n",
    "    \"product_reviews/helsingborg_dresser_reviews.md\",\n",
    "    \"product_reviews/jonkoping_coffee_table_reviews.md\",\n",
    "    \"product_reviews/linkoping_bed_reviews.md\",\n",
    "    \"product_reviews/malmo_desk_reviews.md\",\n",
    "    \"product_reviews/norrkoping_nightstand_reviews.md\",\n",
    "    \"product_reviews/orebro_lamp_reviews.md\",\n",
    "    \"product_reviews/stockholm_chair_reviews.md\",\n",
    "    \"product_reviews/uppsala_sofa_reviews.md\",\n",
    "    \"product_reviews/vasteras_bookshelf_reviews.md\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf57fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approved entities from the `ner_agent` of Lesson 7\n",
    "approved_entities = ['Product', 'Issue', 'Feature', 'Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341565e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approved fact types from the `relevant_fact_agent` of Lesson 7\n",
    "approved_fact_types = {'has_issue': {'subject_label': 'Product', 'predicate_label': 'has_issue', 'object_label': 'Issue'}, 'includes_feature': {'subject_label': 'Product', 'predicate_label': 'includes_feature', 'object_label': 'Feature'}, 'used_in_location': {'subject_label': 'Product', 'predicate_label': 'used_in_location', 'object_label': 'Location'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629dcde",
   "metadata": {},
   "source": [
    "### 8.3 Tool Definitions for loading, chunking and entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5224bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    " \n",
    "# for example, creating a KG pipeline requires these arguments\n",
    "if False:\n",
    "    example = SimpleKGPipeline(\n",
    "        llm=None, # the LLM to use for Entity and Relation extraction\n",
    "        driver=None,  # a neo4j driver to write results to graph\n",
    "        embedder=None,  # an Embedder for chunks\n",
    "        from_pdf=True,   # sortof True because you will use a custom loader\n",
    "        pdf_loader=None, # the custom loader for Markdown\n",
    "        text_splitter=None, # the splitter you defined above\n",
    "        schema=None, # that you just defined above\n",
    "        prompt_template=None, # the template used for entity extraction on each chunk\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7864fa1",
   "metadata": {},
   "source": [
    "## 8.3.2 Text-Splitter for Chunking up the Markdown\n",
    "Define a custom text splitter that uses regex patterns to chunk markdown text. This splitter breaks documents at specified delimiters (like \"---\") to create meaningful text segments for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4fcb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.experimental.components.text_splitters.base import TextSplitter\n",
    "from neo4j_graphrag.experimental.components.types import TextChunk, TextChunks\n",
    "\n",
    "# Define a custom text splitter. Chunking strategy could be yet-another-agent\n",
    "class RegexTextSplitter(TextSplitter):\n",
    "    \"\"\"Split text using regex matched delimiters.\"\"\"\n",
    "    def __init__(self, re: str):\n",
    "        self.re = re\n",
    "    \n",
    "    async def run(self, text: str) -> TextChunks:\n",
    "        \"\"\"Splits a piece of text into chunks.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be split.\n",
    "\n",
    "        Returns:\n",
    "            TextChunks: A list of chunks.\n",
    "        \"\"\"\n",
    "        texts = re.split(self.re, text)\n",
    "        i = 0\n",
    "        chunks = [TextChunk(text=str(text), index=i) for (i, text) in enumerate(texts)]\n",
    "        return TextChunks(chunks=chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b7459",
   "metadata": {},
   "source": [
    "## 8.3.3 Custom Markdown Data Loader\n",
    "This custom loader adapts the Neo4j GraphRAG PDF loader to work with markdown files. It reads markdown content, extracts the document title from the first H1 header, and wraps it in the expected document format for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ad817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom file data loader\n",
    "\n",
    "from neo4j_graphrag.experimental.components.pdf_loader import DataLoader\n",
    "from neo4j_graphrag.experimental.components.types import PdfDocument, DocumentInfo\n",
    "\n",
    "class MarkdownDataLoader(DataLoader):\n",
    "    def extract_title(self,markdown_text):\n",
    "        # Define a regex pattern to match the first h1 header\n",
    "        pattern = r'^# (.+)$'\n",
    "\n",
    "        # Search for the first match in the markdown text\n",
    "        match = re.search(pattern, markdown_text, re.MULTILINE)\n",
    "\n",
    "        # Return the matched group if found\n",
    "        return match.group(1) if match else \"Untitled\"\n",
    "\n",
    "    async def run(self, filepath: Path, metadata = {}) -> PdfDocument:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            markdown_text = f.read()\n",
    "        doc_headline = self.extract_title(markdown_text)\n",
    "        markdown_info = DocumentInfo(\n",
    "            path=str(filepath),\n",
    "            metadata={\n",
    "                \"title\": doc_headline,\n",
    "            }\n",
    "        )\n",
    "        return PdfDocument(text=markdown_text, document_info=markdown_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea0d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# create an OpenAI client for use by Neo4j GraphRAG\n",
    "llm_for_neo4j = OpenAILLM(model_name=\"gpt-4o\", model_params={\"temperature\": 0})\n",
    "\n",
    "# use OpenAI for creating embeddings\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# use the same driver set up by neo4j_for_adk.py\n",
    "neo4j_driver = graphdb.get_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1aaf2",
   "metadata": {},
   "source": [
    "## 8.3.5 Entity Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b53d424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_node_types:  ['Product', 'Issue', 'Feature', 'Location']\n"
     ]
    }
   ],
   "source": [
    "# approved entities list can be used directly \n",
    "schema_node_types = approved_entities\n",
    "\n",
    "print(\"schema_node_types: \", schema_node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b9ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_relationship_types:  ['HAS_ISSUE', 'INCLUDES_FEATURE', 'USED_IN_LOCATION']\n"
     ]
    }
   ],
   "source": [
    "# the keys from approved fact types dictionary can be used for relationship types\n",
    "schema_relationship_types = [key.upper() for key in approved_fact_types.keys()]\n",
    "\n",
    "print(\"schema_relationship_types: \", schema_relationship_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb9c917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_patterns: [['Product', 'HAS_ISSUE', 'Issue'], ['Product', 'INCLUDES_FEATURE', 'Feature'], ['Product', 'USED_IN_LOCATION', 'Location']]\n"
     ]
    }
   ],
   "source": [
    "# rewrite the fact types into a list of tuples\n",
    "schema_patterns = [\n",
    "    [ fact['subject_label'], fact['predicate_label'].upper(), fact['object_label'] ]\n",
    "    for fact in approved_fact_types.values()\n",
    "]\n",
    "\n",
    "print(\"schema_patterns:\", schema_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf6f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the complete entity schema\n",
    "entity_schema = {\n",
    "    \"node_types\": schema_node_types,\n",
    "    \"relationship_types\": schema_relationship_types,\n",
    "    \"patterns\": schema_patterns,\n",
    "    \"additional_node_types\": False, # True would be less strict, allowing unknown node types\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef8625",
   "metadata": {},
   "source": [
    "### 8.3.6 Contexualized Entity Extraction Prompt\n",
    "This helper function extracts the first few lines from a file to provide context for entity extraction. This context helps the LLM better understand the document structure and content when processing individual chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81993656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_context(file_path:str, num_lines=5) -> str:\n",
    "    \"\"\"Helper function to extract the first few lines of a file\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file\n",
    "        num_lines (int, optional): Number of lines to extract. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        str: First few lines of the file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = []\n",
    "        for _ in range(num_lines):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            lines.append(line)\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f6b83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per-chunk entity extraction prompt, with context\n",
    "def contextualize_er_extraction_prompt(context:str) -> str:\n",
    "    \"\"\"Creates a prompt with pre-amble file content for context during entity+relationship extraction.\n",
    "    The context is concatenated into the string, which later will be used as a template\n",
    "    for values like {schema} and {text}.\n",
    "    \"\"\"\n",
    "    general_instructions = \"\"\"\n",
    "    You are a top-tier algorithm designed for extracting\n",
    "    information in structured formats to build a knowledge graph.\n",
    "\n",
    "    Extract the entities (nodes) and specify their type from the following text.\n",
    "    Also extract the relationships between these nodes.\n",
    "\n",
    "    Return result as JSON using the following format:\n",
    "    {{\"nodes\": [ {{\"id\": \"0\", \"label\": \"Person\", \"properties\": {{\"name\": \"John\"}} }}],\n",
    "    \"relationships\": [{{\"type\": \"KNOWS\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"since\": \"2024-08-01\"}} }}] }}\n",
    "\n",
    "    Use only the following node and relationship types (if provided):\n",
    "    {schema}\n",
    "\n",
    "    Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
    "    Do respect the source and target node types for relationship and\n",
    "    the relationship direction.\n",
    "\n",
    "    Make sure you adhere to the following rules to produce valid JSON objects:\n",
    "    - Do not return any additional information other than the JSON in it.\n",
    "    - Omit any backticks around the JSON - simply output the JSON on its own.\n",
    "    - The JSON object must not wrapped into a list - it is its own JSON object.\n",
    "    - Property names must be enclosed in double quotes\n",
    "    \"\"\"\n",
    "\n",
    "    context_goes_here = f\"\"\"\n",
    "    Consider the following context to help identify entities and relationships:\n",
    "    <context>\n",
    "    {context}  \n",
    "    </context>\"\"\"\n",
    "    \n",
    "    input_goes_here = \"\"\"\n",
    "    Input text:\n",
    "\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    return general_instructions + \"\\n\" + context_goes_here + \"\\n\" + input_goes_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed55d8",
   "metadata": {},
   "source": [
    "## 8.4 Make and Use the Knowledge Graph (KG) builder\n",
    "This function creates a customized KG builder pipeline for a specific file by extracting file context and creating a contextualized extraction prompt. It combines all the previously defined components (loader, splitter, schema, LLM) into a complete pipeline.\n",
    "\n",
    "Process each approved markdown file by creating a KG builder pipeline and running it asynchronously. This extracts entities and relationships from the text chunks and stores them in the Neo4j database as the subject graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29dd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kg_builder(file_path:str) -> SimpleKGPipeline:\n",
    "    \"\"\"Builds a KG builder for a given file, which is used to contextualize the chunking and entity extraction.\"\"\"\n",
    "    context = file_context(file_path)\n",
    "    contextualized_prompt = contextualize_er_extraction_prompt(context)\n",
    "    print(contextualized_prompt)\n",
    "\n",
    "    return SimpleKGPipeline(\n",
    "        llm=llm_for_neo4j, # the LLM to use for Entity and Relation extraction\n",
    "        driver=neo4j_driver,  # a neo4j driver to write results to graph\n",
    "        embedder=embedder,  # an Embedder for chunks\n",
    "        from_pdf=True,   # sortof True because you will use a custom loader\n",
    "        pdf_loader=MarkdownDataLoader(), # the custom loader for Markdown\n",
    "        text_splitter=RegexTextSplitter(\"---\"), # the splitter you defined above\n",
    "        schema=entity_schema, # that you just defined above\n",
    "        prompt_template=contextualized_prompt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb73644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ifilimon/Documents/neo4j/import\n",
      "Processing file: /Users/ifilimon/Documents/neo4j/import/product_reviews/gothenburg_table_reviews.md\n",
      "\n",
      "    You are a top-tier algorithm designed for extracting\n",
      "    information in structured formats to build a knowledge graph.\n",
      "\n",
      "    Extract the entities (nodes) and specify their type from the following text.\n",
      "    Also extract the relationships between these nodes.\n",
      "\n",
      "    Return result as JSON using the following format:\n",
      "    {{\"nodes\": [ {{\"id\": \"0\", \"label\": \"Person\", \"properties\": {{\"name\": \"John\"}} }}],\n",
      "    \"relationships\": [{{\"type\": \"KNOWS\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"since\": \"2024-08-01\"}} }}] }}\n",
      "\n",
      "    Use only the following node and relationship types (if provided):\n",
      "    {schema}\n",
      "\n",
      "    Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
      "    Do respect the source and target node types for relationship and\n",
      "    the relationship direction.\n",
      "\n",
      "    Make sure you adhere to the following rules to produce valid JSON objects:\n",
      "    - Do not return any additional information other than the JSON in it.\n",
      "    - Omit any backticks around the JSON - simply output the JSON on its own.\n",
      "    - The JSON object must not wrapped into a list - it is its own JSON object.\n",
      "    - Property names must be enclosed in double quotes\n",
      "    \n",
      "\n",
      "    Consider the following context to help identify entities and relationships:\n",
      "    <context>\n",
      "    # Gothenburg Table Reviews\n",
      "\n",
      "\n",
      "\n",
      "Scraped from https://www.between2furns.com/Gothenburg-Table/dp/B0BQJWJWJW\n",
      "\n",
      "\n",
      "\n",
      "## Rating: ★★★★★ (5/5)\n",
      "  \n",
      "    </context>\n",
      "\n",
      "    Input text:\n",
      "\n",
      "    {text}\n",
      "    \n",
      "\tResults: {'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': None}}\n",
      "Processing file: /Users/ifilimon/Documents/neo4j/import/product_reviews/helsingborg_dresser_reviews.md\n",
      "\n",
      "    You are a top-tier algorithm designed for extracting\n",
      "    information in structured formats to build a knowledge graph.\n",
      "\n",
      "    Extract the entities (nodes) and specify their type from the following text.\n",
      "    Also extract the relationships between these nodes.\n",
      "\n",
      "    Return result as JSON using the following format:\n",
      "    {{\"nodes\": [ {{\"id\": \"0\", \"label\": \"Person\", \"properties\": {{\"name\": \"John\"}} }}],\n",
      "    \"relationships\": [{{\"type\": \"KNOWS\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"since\": \"2024-08-01\"}} }}] }}\n",
      "\n",
      "    Use only the following node and relationship types (if provided):\n",
      "    {schema}\n",
      "\n",
      "    Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
      "    Do respect the source and target node types for relationship and\n",
      "    the relationship direction.\n",
      "\n",
      "    Make sure you adhere to the following rules to produce valid JSON objects:\n",
      "    - Do not return any additional information other than the JSON in it.\n",
      "    - Omit any backticks around the JSON - simply output the JSON on its own.\n",
      "    - The JSON object must not wrapped into a list - it is its own JSON object.\n",
      "    - Property names must be enclosed in double quotes\n",
      "    \n",
      "\n",
      "    Consider the following context to help identify entities and relationships:\n",
      "    <context>\n",
      "    # Helsingborg Dresser Reviews\n",
      "\n",
      "\n",
      "\n",
      "Scraped from https://www.between2furns.com/Helsingborg-Dresser/dp/B0BQJWJWJW\n",
      "\n",
      "\n",
      "\n",
      "## Rating: ★★★☆☆ (3/5)\n",
      "  \n",
      "    </context>\n",
      "\n",
      "    Input text:\n",
      "\n",
      "    {text}\n",
      "    \n",
      "\tResults: {'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': None}}\n",
      "Processing file: /Users/ifilimon/Documents/neo4j/import/product_reviews/jonkoping_coffee_table_reviews.md\n",
      "\n",
      "    You are a top-tier algorithm designed for extracting\n",
      "    information in structured formats to build a knowledge graph.\n",
      "\n",
      "    Extract the entities (nodes) and specify their type from the following text.\n",
      "    Also extract the relationships between these nodes.\n",
      "\n",
      "    Return result as JSON using the following format:\n",
      "    {{\"nodes\": [ {{\"id\": \"0\", \"label\": \"Person\", \"properties\": {{\"name\": \"John\"}} }}],\n",
      "    \"relationships\": [{{\"type\": \"KNOWS\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"since\": \"2024-08-01\"}} }}] }}\n",
      "\n",
      "    Use only the following node and relationship types (if provided):\n",
      "    {schema}\n",
      "\n",
      "    Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
      "    Do respect the source and target node types for relationship and\n",
      "    the relationship direction.\n",
      "\n",
      "    Make sure you adhere to the following rules to produce valid JSON objects:\n",
      "    - Do not return any additional information other than the JSON in it.\n",
      "    - Omit any backticks around the JSON - simply output the JSON on its own.\n",
      "    - The JSON object must not wrapped into a list - it is its own JSON object.\n",
      "    - Property names must be enclosed in double quotes\n",
      "    \n",
      "\n",
      "    Consider the following context to help identify entities and relationships:\n",
      "    <context>\n",
      "    # Jönköping Coffee Table Reviews\n",
      "\n",
      "\n",
      "\n",
      "Scraped from https://www.between2furns.com/Jonkoping-Coffee-Table/dp/B0BQJWJWJW\n",
      "\n",
      "\n",
      "\n",
      "## Rating: ★★★★★ (5/5)\n",
      "  \n",
      "    </context>\n",
      "\n",
      "    Input text:\n",
      "\n",
      "    {text}\n",
      "    \n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     kg_builder = make_kg_builder(file_path)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m kg_builder.run_async(file_path=\u001b[38;5;28mstr\u001b[39m(file_path))\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mResults:\u001b[39m\u001b[33m\"\u001b[39m, results.result)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll files processed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/kg_builder.py:160\u001b[39m, in \u001b[36mSimpleKGPipeline.run_async\u001b[39m\u001b[34m(self, file_path, text)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_async\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m, file_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, text: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m ) -> PipelineResult:\n\u001b[32m    150\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m    Asynchronously runs the knowledge graph building process.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        PipelineResult: The result of the pipeline execution.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.runner.run({\u001b[33m\"\u001b[39m\u001b[33mfile_path\u001b[39m\u001b[33m\"\u001b[39m: file_path, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/config/runner.py:130\u001b[39m, in \u001b[36mPipelineRunner.run\u001b[39m\u001b[34m(self, user_input)\u001b[39m\n\u001b[32m    126\u001b[39m     run_param = deep_update(\u001b[38;5;28mself\u001b[39m.run_params, user_input)\n\u001b[32m    127\u001b[39m logger.info(\n\u001b[32m    128\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPIPELINE_RUNNER: starting pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.pipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with run_params=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(run_param)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline.run(data=run_param)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_cleaning:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:573\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    571\u001b[39m orchestrator = Orchestrator(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    572\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPIPELINE ORCHESTRATOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m orchestrator.run(data)\n\u001b[32m    574\u001b[39m end_time = default_timer()\n\u001b[32m    575\u001b[39m logger.debug(\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPIPELINE FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:270\u001b[39m, in \u001b[36mOrchestrator.run\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_pipeline_started(\u001b[38;5;28mself\u001b[39m.run_id, data)\n\u001b[32m    269\u001b[39m tasks = [\u001b[38;5;28mself\u001b[39m.run_task(root, data) \u001b[38;5;28;01mfor\u001b[39;00m root \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline.roots()]\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_pipeline_finished(\n\u001b[32m    272\u001b[39m     \u001b[38;5;28mself\u001b[39m.run_id, \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline.get_final_results(\u001b[38;5;28mself\u001b[39m.run_id)\n\u001b[32m    273\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001b[39m, in \u001b[36mOrchestrator.run_task\u001b[39m\u001b[34m(self, task, data)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_task_finished(\u001b[38;5;28mself\u001b[39m.run_id, task.name, res)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001b[39m, in \u001b[36mOrchestrator.on_task_complete\u001b[39m\u001b[34m(self, data, task, result)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_result_for_component(\n\u001b[32m    130\u001b[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001b[32m    131\u001b[39m )\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[\u001b[38;5;28mself\u001b[39m.run_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(task)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001b[39m, in \u001b[36mOrchestrator.run_task\u001b[39m\u001b[34m(self, task, data)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_task_finished(\u001b[38;5;28mself\u001b[39m.run_id, task.name, res)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001b[39m, in \u001b[36mOrchestrator.on_task_complete\u001b[39m\u001b[34m(self, data, task, result)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_result_for_component(\n\u001b[32m    130\u001b[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001b[32m    131\u001b[39m )\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[\u001b[38;5;28mself\u001b[39m.run_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(task)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001b[39m, in \u001b[36mOrchestrator.run_task\u001b[39m\u001b[34m(self, task, data)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_task_finished(\u001b[38;5;28mself\u001b[39m.run_id, task.name, res)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001b[39m, in \u001b[36mOrchestrator.on_task_complete\u001b[39m\u001b[34m(self, data, task, result)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_result_for_component(\n\u001b[32m    130\u001b[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001b[32m    131\u001b[39m )\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[\u001b[38;5;28mself\u001b[39m.run_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(task)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:89\u001b[39m, in \u001b[36mOrchestrator.run_task\u001b[39m\u001b[34m(self, task, data)\u001b[39m\n\u001b[32m     83\u001b[39m notifier = partial(\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mself\u001b[39m.event_notifier.notify_task_progress,\n\u001b[32m     85\u001b[39m     run_id=\u001b[38;5;28mself\u001b[39m.run_id,\n\u001b[32m     86\u001b[39m     task_name=task.name,\n\u001b[32m     87\u001b[39m )\n\u001b[32m     88\u001b[39m context = RunContext(run_id=\u001b[38;5;28mself\u001b[39m.run_id, task_name=task.name, notifier=notifier)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m res = \u001b[38;5;28;01mawait\u001b[39;00m task.run(context, inputs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.set_task_status(task.name, RunStatus.DONE)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_notifier.notify_task_finished(\u001b[38;5;28mself\u001b[39m.run_id, task.name, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:104\u001b[39m, in \u001b[36mTaskPipelineNode.run\u001b[39m\u001b[34m(self, context, inputs)\u001b[39m\n\u001b[32m    102\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTASK START \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m input=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m start_time = default_timer()\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m res = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execute(context, inputs)\n\u001b[32m    105\u001b[39m end_time = default_timer()\n\u001b[32m    106\u001b[39m logger.debug(\n\u001b[32m    107\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTASK FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m res=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(res)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:90\u001b[39m, in \u001b[36mTaskPipelineNode.execute\u001b[39m\u001b[34m(self, context, inputs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m, context: RunContext, inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[32m     82\u001b[39m ) -> RunResult | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     83\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m        was unsuccessful.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     component_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.component.run_with_context(\n\u001b[32m     91\u001b[39m         context_=context, **inputs\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     93\u001b[39m     run_result = RunResult(\n\u001b[32m     94\u001b[39m         result=component_result,\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m run_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/component.py:110\u001b[39m, in \u001b[36mComponent.run_with_context\u001b[39m\u001b[34m(self, context_, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This method is called by the pipeline orchestrator.\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03mThe `context_` parameter contains information about\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mthe pipeline run: the `run_id` and a `notify` function\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03mIt defaults to calling the `run` method to prevent any breaking change.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# default behavior to prevent a breaking change\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:34\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m wrapper(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:338\u001b[39m, in \u001b[36mLLMEntityRelationExtractor.run\u001b[39m\u001b[34m(self, chunks, document_info, lexical_graph_config, schema, examples, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m sem = asyncio.Semaphore(\u001b[38;5;28mself\u001b[39m.max_concurrency)\n\u001b[32m    328\u001b[39m tasks = [\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m.run_for_chunk(\n\u001b[32m    330\u001b[39m         sem,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks.chunks\n\u001b[32m    337\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m chunk_graphs: \u001b[38;5;28mlist\u001b[39m[Neo4jGraph] = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks))\n\u001b[32m    339\u001b[39m graph = \u001b[38;5;28mself\u001b[39m.combine_chunk_graphs(lexical_graph, chunk_graphs)\n\u001b[32m    340\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted graph: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(graph)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agentic-kg-iRiaRh-y-py3.11/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:278\u001b[39m, in \u001b[36mLLMEntityRelationExtractor.run_for_chunk\u001b[39m\u001b[34m(self, sem, chunk, schema, examples, lexical_graph_builder)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_for_chunk\u001b[39m(\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    271\u001b[39m     sem: asyncio.Semaphore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     lexical_graph_builder: Optional[LexicalGraphBuilder] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Neo4jGraph:\n\u001b[32m    277\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run extraction, validation and post processing for a single chunk\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[32m    279\u001b[39m         chunk_graph = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.extract_for_chunk(schema, examples, chunk)\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# final_chunk_graph = self.validate_chunk(chunk_graph, schema)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.10/lib/python3.11/asyncio/locks.py:15\u001b[39m, in \u001b[36m_ContextManagerMixin.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.acquire()\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# statement for locks.\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.10/lib/python3.11/asyncio/locks.py:387\u001b[39m, in \u001b[36mSemaphore.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    389\u001b[39m         \u001b[38;5;28mself\u001b[39m._waiters.remove(fut)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from helper import get_neo4j_import_dir\n",
    "\n",
    "neo4j_import_dir = get_neo4j_import_dir() or \".\"\n",
    "print(neo4j_import_dir)\n",
    "for file_name in approved_files:\n",
    "    file_path = os.path.join(neo4j_import_dir, file_name)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    kg_builder = make_kg_builder(file_path)\n",
    "    results = await kg_builder.run_async(file_path=str(file_path))\n",
    "    print(\"\\tResults:\", results.result)\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07dc1a8",
   "metadata": {},
   "source": [
    "### GraphRAG documentation here: https://graphrag.com/reference/knowledge-graph/domain-graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832a369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-kg-iRiaRh-y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
